{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHKiT Environmental Contours\n",
    "\n",
    "Environmental contours of extreme sea states can be used as a part of reliability-based design for offshore structures, including wave energy converters (WECs). Environmental contours provide estimations of extreme sea states based on short-term data (e.g. 10 years used to estimate a 100-year event). These environmental contours describe extreme sea states by characterizing the resource, defining sea states for extreme condition analysis, and developing a framework for analyzing survivability of a design.\n",
    "\n",
    "MHKiT includes functions adapted from the [WDRT](https://github.com/WEC-Sim/WDRT) for creating environmental contours of extreme sea states using a principal component analysis (PCA) methodology, with additional improvements for characterizing the joint probability distribution of sea states. As a demonstration, this notebook will walk through the following steps to find a 100-year sea state for NDBC buoy 46022 using 16 years of spectral wave density data.\n",
    "\n",
    " 1. Request Spectral Wave Density Data from NDBC\n",
    " 2. Calculate Hm0 and Te using the requested data\n",
    " 3. Find the data's 100-year contour\n",
    " 4. Plot the data and the 100-year contour\n",
    "\n",
    "We will start by importing the necessary python packages (`scipy`, `pandas`, `numpy`), and MHKiT wave submodules (`resource`, `graphics`, and `io.ndbc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhkit.wave import resource, graphics\n",
    "import matplotlib.pyplot as plt\n",
    "from mhkit.wave.io import ndbc\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Request Spectral Wave Density Data from NDBC\n",
    "   \n",
    "MHKiT can be used to request historical data from the National Data Buoy Center ([NDBC](https://www.ndbc.noaa.gov/)). This process is split into the following steps:\n",
    "\n",
    "- Query available NDBC data  \n",
    "- Select years of interest \n",
    "- Request Data from NDBC\n",
    "- Convert the DataFrames to DateTime Index\n",
    " \n",
    "\n",
    "### Query available NDBC data  \n",
    "Looking at the help for the `ndbc.available_data` function (`help(ndbc.available_data)`) the function requires a parameter to be specified and optionally the user may provide a station ID as a string. We are interested in historical spectral wave density data `'swden'` (from which we may calculate Hm0 and Te). Additionally, we will specify the buoy number as `'46022'` to only return data associated with this site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>46022</td>\n",
       "      <td>1996</td>\n",
       "      <td>46022w1996.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>46022</td>\n",
       "      <td>1997</td>\n",
       "      <td>46022w1997.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>46022</td>\n",
       "      <td>1998</td>\n",
       "      <td>46022w1998.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>46022</td>\n",
       "      <td>1999</td>\n",
       "      <td>46022w1999.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>46022</td>\n",
       "      <td>2000</td>\n",
       "      <td>46022w2000.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>46022</td>\n",
       "      <td>2001</td>\n",
       "      <td>46022w2001.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>46022</td>\n",
       "      <td>2002</td>\n",
       "      <td>46022w2002.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>46022</td>\n",
       "      <td>2003</td>\n",
       "      <td>46022w2003.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>46022</td>\n",
       "      <td>2004</td>\n",
       "      <td>46022w2004.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>46022</td>\n",
       "      <td>2005</td>\n",
       "      <td>46022w2005.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>46022</td>\n",
       "      <td>2006</td>\n",
       "      <td>46022w2006.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>46022</td>\n",
       "      <td>2007</td>\n",
       "      <td>46022w2007.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>46022</td>\n",
       "      <td>2008</td>\n",
       "      <td>46022w2008.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>46022</td>\n",
       "      <td>2009</td>\n",
       "      <td>46022w2009.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>46022</td>\n",
       "      <td>2010</td>\n",
       "      <td>46022w2010.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>46022</td>\n",
       "      <td>2011</td>\n",
       "      <td>46022w2011.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>46022</td>\n",
       "      <td>2012</td>\n",
       "      <td>46022w2012.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>46022</td>\n",
       "      <td>2013</td>\n",
       "      <td>46022w2013.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>46022</td>\n",
       "      <td>2014</td>\n",
       "      <td>46022w2014.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>46022</td>\n",
       "      <td>2015</td>\n",
       "      <td>46022w2015.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>46022</td>\n",
       "      <td>2016</td>\n",
       "      <td>46022w2016.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>46022</td>\n",
       "      <td>2017</td>\n",
       "      <td>46022w2017.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>46022</td>\n",
       "      <td>2018</td>\n",
       "      <td>46022w2018.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>46022</td>\n",
       "      <td>2019</td>\n",
       "      <td>46022w2019.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>46022</td>\n",
       "      <td>2004</td>\n",
       "      <td>46022wb2004.txt.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  year            filename\n",
       "1414  46022  1996   46022w1996.txt.gz\n",
       "1415  46022  1997   46022w1997.txt.gz\n",
       "1416  46022  1998   46022w1998.txt.gz\n",
       "1417  46022  1999   46022w1999.txt.gz\n",
       "1418  46022  2000   46022w2000.txt.gz\n",
       "1419  46022  2001   46022w2001.txt.gz\n",
       "1420  46022  2002   46022w2002.txt.gz\n",
       "1421  46022  2003   46022w2003.txt.gz\n",
       "1422  46022  2004   46022w2004.txt.gz\n",
       "1423  46022  2005   46022w2005.txt.gz\n",
       "1424  46022  2006   46022w2006.txt.gz\n",
       "1425  46022  2007   46022w2007.txt.gz\n",
       "1426  46022  2008   46022w2008.txt.gz\n",
       "1427  46022  2009   46022w2009.txt.gz\n",
       "1428  46022  2010   46022w2010.txt.gz\n",
       "1429  46022  2011   46022w2011.txt.gz\n",
       "1430  46022  2012   46022w2012.txt.gz\n",
       "1431  46022  2013   46022w2013.txt.gz\n",
       "1432  46022  2014   46022w2014.txt.gz\n",
       "1433  46022  2015   46022w2015.txt.gz\n",
       "1434  46022  2016   46022w2016.txt.gz\n",
       "1435  46022  2017   46022w2017.txt.gz\n",
       "1436  46022  2018   46022w2018.txt.gz\n",
       "1437  46022  2019   46022w2019.txt.gz\n",
       "1438  46022  2004  46022wb2004.txt.gz"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the parameter as spectral wave density and the buoy number to be 46022\n",
    "parameter = 'swden'\n",
    "buoy_number = '46022' \n",
    "ndbc_available_data= ndbc.available_data(parameter, buoy_number)\n",
    "ndbc_available_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select years of interest\n",
    "\n",
    "The `ndbc.available_data` function has returned a DataFrame with columns 'id', 'year', and 'filename'. The year column is of type int while the filename and id (5 digit alpha-numeric specifier) are of type string. In this case, the years returned from `ndbc_available_data` span  1996 to the last complete year the buoy was operational (currently 2019 for 46022). For demonstration, we have decided we are interested in the data between the years 1996 and 2012 so we will create a new `years_of_interest` DataFrame which only contains years less than 2013.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>46022</td>\n",
       "      <td>1996</td>\n",
       "      <td>46022w1996.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>46022</td>\n",
       "      <td>1997</td>\n",
       "      <td>46022w1997.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>46022</td>\n",
       "      <td>1998</td>\n",
       "      <td>46022w1998.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>46022</td>\n",
       "      <td>1999</td>\n",
       "      <td>46022w1999.txt.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>46022</td>\n",
       "      <td>2000</td>\n",
       "      <td>46022w2000.txt.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  year           filename\n",
       "1414  46022  1996  46022w1996.txt.gz\n",
       "1415  46022  1997  46022w1997.txt.gz\n",
       "1416  46022  1998  46022w1998.txt.gz\n",
       "1417  46022  1999  46022w1999.txt.gz\n",
       "1418  46022  2000  46022w2000.txt.gz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice the available data to only include through year 2012\n",
    "years_of_interest = ndbc_available_data[ndbc_available_data.year < 2013]\n",
    "years_of_interest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Data from NDBC\n",
    "\n",
    "The filename column in our `years_of_interest` DataFrame and the parameter is needed to request the data. To get the data we can use the `ndbc.request_data` function to iterate over each buoy id and year in the passed DataFrame. This function will return the parameter data as a dictionary of DataFrames which may be accessed by buoy id and then the year for multiple buoys or just the year for a single buoy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionary of parameter data by year\n",
    "filenames= years_of_interest['filename']\n",
    "ndbc_requested_data = ndbc.request_data(parameter, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the DataFrames to DateTime Index\n",
    "\n",
    "The data returned for each year has a variable number of columns for the year, month, day, hour, minute, and the way the columns are formatted (this is a primary reason for return a dictionary of DataFrames indexed by years). A common step a user will want to take is to remove the inconsistent NDBC date/ time columns and create a standard DateTime index. The MHKiT function `ndbc.to_datetime_index` will perform this standardization by parsing the NDBC date/ time columns into DateTime format and setting this as the DataFrame Index and removing the NDBC date/ time columns. This function operates on a DateFrame therefore we will iterate over each year of the `ndbc_requested_data` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.03</th>\n",
       "      <th>0.04</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.06</th>\n",
       "      <th>0.07</th>\n",
       "      <th>0.08</th>\n",
       "      <th>0.09</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.12</th>\n",
       "      <th>...</th>\n",
       "      <th>0.31</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>27.49</td>\n",
       "      <td>41.63</td>\n",
       "      <td>27.23</td>\n",
       "      <td>17.09</td>\n",
       "      <td>8.61</td>\n",
       "      <td>5.05</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>25.13</td>\n",
       "      <td>57.69</td>\n",
       "      <td>32.59</td>\n",
       "      <td>11.75</td>\n",
       "      <td>6.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.22</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>15.98</td>\n",
       "      <td>48.98</td>\n",
       "      <td>37.98</td>\n",
       "      <td>23.56</td>\n",
       "      <td>11.87</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>14.73</td>\n",
       "      <td>38.55</td>\n",
       "      <td>34.99</td>\n",
       "      <td>14.79</td>\n",
       "      <td>9.23</td>\n",
       "      <td>5.54</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>22.77</td>\n",
       "      <td>52.11</td>\n",
       "      <td>34.88</td>\n",
       "      <td>18.90</td>\n",
       "      <td>13.36</td>\n",
       "      <td>7.49</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0.03  0.04   0.05   0.06   0.07   0.08   0.09  0.10  \\\n",
       "date                                                                       \n",
       "1996-01-01 00:00:00   0.0  2.11  27.49  41.63  27.23  17.09   8.61  5.05   \n",
       "1996-01-01 01:00:00   0.0  1.20  25.13  57.69  32.59  11.75   6.33  4.16   \n",
       "1996-01-01 02:00:00   0.0  0.90  15.98  48.98  37.98  23.56  11.87  6.80   \n",
       "1996-01-01 03:00:00   0.0  0.38  14.73  38.55  34.99  14.79   9.23  5.54   \n",
       "1996-01-01 04:00:00   0.0  0.12  22.77  52.11  34.88  18.90  13.36  7.49   \n",
       "\n",
       "                     0.11  0.12  ...  0.31  0.32  0.33  0.34  0.35  0.36  \\\n",
       "date                             ...                                       \n",
       "1996-01-01 00:00:00  3.73  2.82  ...  0.17  0.16  0.14  0.15  0.13  0.09   \n",
       "1996-01-01 01:00:00  4.22  2.98  ...  0.22  0.18  0.20  0.10  0.12  0.10   \n",
       "1996-01-01 02:00:00  3.75  3.00  ...  0.14  0.15  0.20  0.12  0.08  0.08   \n",
       "1996-01-01 03:00:00  4.43  2.99  ...  0.17  0.20  0.17  0.14  0.12  0.09   \n",
       "1996-01-01 04:00:00  2.94  2.55  ...  0.12  0.11  0.09  0.13  0.10  0.08   \n",
       "\n",
       "                     0.37  0.38  0.39  0.40  \n",
       "date                                         \n",
       "1996-01-01 00:00:00  0.09  0.08  0.06  0.06  \n",
       "1996-01-01 01:00:00  0.07  0.07  0.05  0.04  \n",
       "1996-01-01 02:00:00  0.07  0.09  0.07  0.05  \n",
       "1996-01-01 03:00:00  0.07  0.05  0.06  0.04  \n",
       "1996-01-01 04:00:00  0.08  0.07  0.03  0.03  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lastly we will convert a DateTime Index \n",
    "ndbc_data={}\n",
    "# Create a Datetime Index and remove NOAA date columns for each year\n",
    "for year in ndbc_requested_data:\n",
    "    year_data = ndbc_requested_data[year]\n",
    "    ndbc_data[year] = ndbc.to_datetime_index(parameter, year_data)\n",
    "\n",
    "# Display DataFrame of 46022 data from 1996\n",
    "ndbc_data['1996'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Hm0 and Te using the NDBC Data\n",
    "\n",
    "A sea state may be characterized by significant wave height (Hm0) and energy period (Te). Using the historical spectral wave density data from NDBC, we can calculate these variables using MHKiT. Both Hm0 and Te return a single value for a given time (e.g. DateTime index). Currently, the data remains as a dictionary of DataFrames because the frequency binning (range and discretization) change across years of NDBC data. Once we have a single value for each DateTime we can combine all the data into a single DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hm0</th>\n",
       "      <th>Te</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-01 00:00:00</th>\n",
       "      <td>4.819627</td>\n",
       "      <td>14.856398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 01:00:00</th>\n",
       "      <td>5.004158</td>\n",
       "      <td>14.961679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 02:00:00</th>\n",
       "      <td>5.091169</td>\n",
       "      <td>14.244618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 03:00:00</th>\n",
       "      <td>4.679487</td>\n",
       "      <td>14.042246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-01 04:00:00</th>\n",
       "      <td>5.140895</td>\n",
       "      <td>14.478961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 19:00:00</th>\n",
       "      <td>1.995194</td>\n",
       "      <td>14.757854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 20:00:00</th>\n",
       "      <td>1.976259</td>\n",
       "      <td>14.360242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 21:00:00</th>\n",
       "      <td>2.658421</td>\n",
       "      <td>15.708162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 22:00:00</th>\n",
       "      <td>2.364910</td>\n",
       "      <td>15.247587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:00:00</th>\n",
       "      <td>2.056891</td>\n",
       "      <td>14.328179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Hm0         Te\n",
       "date                                    \n",
       "1996-01-01 00:00:00  4.819627  14.856398\n",
       "1996-01-01 01:00:00  5.004158  14.961679\n",
       "1996-01-01 02:00:00  5.091169  14.244618\n",
       "1996-01-01 03:00:00  4.679487  14.042246\n",
       "1996-01-01 04:00:00  5.140895  14.478961\n",
       "...                       ...        ...\n",
       "2012-12-31 19:00:00  1.995194  14.757854\n",
       "2012-12-31 20:00:00  1.976259  14.360242\n",
       "2012-12-31 21:00:00  2.658421  15.708162\n",
       "2012-12-31 22:00:00  2.364910  15.247587\n",
       "2012-12-31 23:00:00  2.056891  14.328179\n",
       "\n",
       "[125410 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intialize empty lists to store the results from each year\n",
    "Hm0_list=[]\n",
    "Te_list=[]\n",
    "\n",
    "# Iterate over each year and save the result in the initalized dictionary\n",
    "for year in ndbc_data:\n",
    "    year_data = ndbc_data[year]\n",
    "    Hm0_list.append(resource.significant_wave_height(year_data.T))\n",
    "    Te_list.append(resource.energy_period(year_data.T))\n",
    "\n",
    "# Concatenate list of Series into a single DataFrame\n",
    "Te = pd.concat(Te_list ,axis=0)\n",
    "Hm0 = pd.concat(Hm0_list ,axis=0)\n",
    "Hm0_Te = pd.concat([Hm0,Te],axis=1)\n",
    "\n",
    "# Drop any NaNs created from the calculation of Hm0 or Te\n",
    "Hm0_Te.dropna(inplace=True)\n",
    "# Sort the DateTime index\n",
    "Hm0_Te.sort_index(inplace=True)\n",
    "Hm0_Te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the contour line for the 100 year\n",
    "\n",
    "With the sea state data calculated, we can now use the modified I-FORM method to define reliability for a 100-year sea state based on the 17 years of spectral wave density data obtained from NDBC for buoy 46022. Reliability is the likelihood that a certain event will not occur in a given period. The period will define a line of constant probability in the joint probability of Hm0 and Te but individually each component different reliability (marginal distribution) which we can find by evaluating a normal cumulative distribution function (CDF). This CDF returns each component's quantiles along the iso-reliability line that finally allows us to calculate each sea state value (e.g. the 100-year contour values for Hm0 and Te). \n",
    "\n",
    "For more detail on the environmental contour method used here please refer to:\n",
    "[Eckert-Gallup et. al 2016](https://www.sciencedirect.com/science/article/abs/pii/S0029801815006721)\n",
    "\n",
    "To apply the environmental contours function we will specify a 100-year sea state, the sea state data (Hm0, Te), and the time difference between measurements (dt in seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return period (years) of interest\n",
    "period = 100  \n",
    "\n",
    "# Remove Hm0 Outliers\n",
    "Hm0_Te_clean = Hm0_Te[Hm0_Te.Hm0 < 20]\n",
    "\n",
    "# Get only the values from the DataFrame\n",
    "Hm0 = Hm0_Te_clean.Hm0.values  \n",
    "Te  = Hm0_Te_clean.Te.values \n",
    "\n",
    "# Delta time of sea-states \n",
    "dt = (Hm0_Te_clean.index[2]-Hm0_Te_clean.index[1]).seconds  \n",
    "\n",
    "# Get the contour values\n",
    "Hm0_contour, Te_contour, PCA = resource.environmental_contour(Hm0, Te, dt, period, return_PCA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot overlay of the data and contour\n",
    "Lastly we can use the MHKiT graphics module to create a contour plot which shows the data and resultant conotour line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "ax = graphics.plot_environmental_contour(Te, Hm0, \n",
    "                                    Te_contour, Hm0_contour, \n",
    "                                    data_label='NDBC 46022', \n",
    "                                    contour_label='100 Year Contour',\n",
    "                                    x_label = 'Energy Period, $Te$ [s]',\n",
    "                                    y_label = 'Sig. wave height, $Hm0$ [m]', \n",
    "                                    ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Clusters\n",
    "\n",
    "Often in resource characterization we want to pick a few representative sea state to run alaysis. To do this with the resource data in python we reccomend using a Gaussian Mixture Model (a more generalized k-means clustering method). Using sckitlearn this is very straigth forward. We combine our Hm0 and Te data into an N x 2 numpy array. We specify our number of components (number of representative sea states) and then call the fit method on the data. Fianlly, using the methods `means_` and `weights` we can organize the results into an easily digestable table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Compute Gaussian Mixture Model\n",
    "X = np.vstack((Te, Hm0)).T\n",
    "gmm = GaussianMixture(n_components=8).fit(X)\n",
    "\n",
    "# Save centers and weights\n",
    "results = pd.DataFrame(gmm.means_, columns=['Te','Hm0'])\n",
    "results['weights'] = gmm.weights_\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Clusters\n",
    "\n",
    "We can visually look at the clusters by predicting which cluster each datapoint belongs in. Then we can plot the means on top of this to show where each cluster is centered and how the data points are being catagorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Sections of Data\n",
    "labels = gmm.predict(X)\n",
    "plt.scatter(Te, Hm0, c=labels, s=40)\n",
    "plt.plot(results.Te, results.Hm0, 'm+')\n",
    "plt.xlabel('Energy Period, $Te$ [s]')\n",
    "plt.ylabel('Sig. wave height, $Hm0$ [m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
